{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a468d762",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING ALGORITHMS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3143e78",
   "metadata": {},
   "source": [
    "# The Iris dataset is a famous and commonly used dataset in machine learning and statistics. It was introduced by the British biologist and statistician Ronald A. Fisher in 1936. This dataset is often used as a benchmark for various classification algorithms and tasks. It contains measurements of four features of three different species of iris flowers: Iris setosa, Iris versicolor, and Iris virginica. The four features are:\n",
    "\n",
    "1. **Sepal Length**: The length of the iris flower's sepal (the green, leaf-like structure that surrounds the petals).\n",
    "\n",
    "2. **Sepal Width**: The width of the iris flower's sepal.\n",
    "\n",
    "3. **Petal Length**: The length of the iris flower's petal (the colorful part of the flower).\n",
    "\n",
    "4. **Petal Width**: The width of the iris flower's petal.\n",
    "\n",
    "Each of these features is measured in centimeters. The goal of using the Iris dataset is typically to classify iris flowers into one of the three species based on these four feature measurements.\n",
    "\n",
    "Here's how you can load the Iris dataset in Python using scikit-learn:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Access the feature matrix (X) and target labels (y)\n",
    "X = iris.data  # Feature matrix\n",
    "y = iris.target  # Target labels (species)\n",
    "```\n",
    "\n",
    "After loading the dataset, you'll have access to `X`, which is a NumPy array containing the feature measurements, and `y`, which is a NumPy array containing the target labels (0 for Iris setosa, 1 for Iris versicolor, and 2 for Iris virginica).\n",
    "\n",
    "The Iris dataset is often used for tasks such as classification, clustering, and dimensionality reduction, making it a widely recognized dataset in the field of machine learning for educational and benchmarking purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84d19c",
   "metadata": {},
   "source": [
    "# IRIS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db9d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0b69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96df832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c967e9",
   "metadata": {},
   "source": [
    "# description of the sklearn.utils._bunch.Bunch\n",
    "`sklearn.utils.Bunch` is a class in scikit-learn (often abbreviated as sklearn), which is a popular machine learning library in Python. This class is used to represent datasets in scikit-learn in a convenient and consistent way.\n",
    "\n",
    "A `Bunch` object is essentially a dictionary-like container that holds various data attributes. It is commonly used to store datasets that are typically used for machine learning tasks. The attributes within a `Bunch` object typically include the following:\n",
    "\n",
    "1. `data`: This attribute stores the actual data matrix or array, often as a NumPy array or a Pandas DataFrame. Each row of this matrix represents an individual data sample, and each column represents a feature.\n",
    "\n",
    "2. `target`: This attribute stores the target variable or labels associated with the data samples. It is often a NumPy array or a Pandas Series. In supervised learning tasks, this is the variable you aim to predict or classify.\n",
    "\n",
    "3. `feature_names`: An optional attribute that contains the names of the features or columns in the `data` attribute. This is useful for keeping track of the feature names when working with datasets.\n",
    "\n",
    "4. `target_names`: An optional attribute that contains the names or labels for the classes in the `target` attribute. This is commonly used in classification tasks to label the different classes.\n",
    "\n",
    "5. `DESCR`: An optional attribute that provides a description or information about the dataset.\n",
    "\n",
    "`Bunch` objects are convenient for packaging and passing datasets because they provide a standardized way to access and manipulate the data and associated metadata. You can access these attributes using dot notation, like `bunch.data` or `bunch.target`, making it easy to work with data in scikit-learn.\n",
    "\n",
    "Here's an example of creating a `Bunch` object to represent a simple dataset:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import Bunch\n",
    "\n",
    "# Create a Bunch object to represent a dataset\n",
    "data = Bunch(\n",
    "    data=[[1, 2], [3, 4], [5, 6]],\n",
    "    target=[0, 1, 0],\n",
    "    feature_names=['feature1', 'feature2'],\n",
    "    target_names=['class0', 'class1'],\n",
    "    DESCR=\"A sample dataset for illustration.\"\n",
    ")\n",
    "\n",
    "# Accessing data attributes\n",
    "print(data.data)\n",
    "print(data.target)\n",
    "print(data.feature_names)\n",
    "print(data.target_names)\n",
    "print(data.DESCR)\n",
    "```\n",
    "\n",
    "In practice, `sklearn.utils.Bunch` is often used when loading and working with datasets from scikit-learn's built-in datasets, making it easier for users to access and manipulate the data in a consistent manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c0a3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printting elements of the iris dataset\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735d9ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting information about the data\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f9ab97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting our values for prediction\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a598dfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the target names\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac84d8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd2168",
   "metadata": {},
   "source": [
    "# DATA MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f862051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extractring the third column of the iris dataset\n",
    "X=iris.data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631402b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.crossvalidation import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92cd13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c16eb9",
   "metadata": {},
   "source": [
    "# DATA RESHAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f978aa",
   "metadata": {},
   "source": [
    "# In the context of machine learning, data reshaping refers to the process of changing the structure or organization of your dataset. This can involve converting data from one format to another or changing the arrangement of data points to make it suitable for a specific machine learning algorithm or task. Data reshaping is an important step in data preprocessing and can include various operations, depending on the nature of your data and the requirements of your machine learning model. Here are some common scenarios in which data reshaping is necessary:\n",
    "\n",
    "1. **Changing Data Structure**:\n",
    "   \n",
    "   - **Converting from Lists/Arrays to DataFrames**: You might have your data stored in lists or NumPy arrays, and you want to convert it to a Pandas DataFrame for easier manipulation and analysis.\n",
    "   \n",
    "   - **Converting from DataFrames to Arrays**: Conversely, you might need to convert a DataFrame into arrays to use it with certain machine learning libraries or algorithms.\n",
    "\n",
    "2. **Reshaping for Specific Algorithms**:\n",
    "\n",
    "   - **Flattening Images**: For image classification tasks, you may need to flatten multi-dimensional image data (e.g., converting 2D images into 1D arrays) to use them with traditional machine learning algorithms like logistic regression.\n",
    "\n",
    "   - **Changing Input Shape**: Some machine learning algorithms, such as Convolutional Neural Networks (CNNs), require specific input shapes (e.g., height x width x channels for images). You may need to reshape your data to match these requirements.\n",
    "\n",
    "3. **Time Series Data**:\n",
    "\n",
    "   - **Sliding Windows**: When working with time series data, you might need to create sliding windows of data for input to recurrent neural networks (RNNs) or other sequence models.\n",
    "\n",
    "4. **One-Hot Encoding**:\n",
    "\n",
    "   - **Converting Categorical Variables**: Categorical variables often need to be one-hot encoded, where each category becomes a binary column. This reshaping is essential when using categorical data in machine learning models.\n",
    "\n",
    "5. **Stacking or Merging Data**:\n",
    "\n",
    "   - **Stacking DataFrames**: You may have data split across multiple DataFrames or files, and you need to stack or merge them together to create a single dataset for analysis.\n",
    "\n",
    "6. **Reshaping for Cross-Validation**:\n",
    "\n",
    "   - **Preparing Data for Cross-Validation**: When performing k-fold cross-validation, you may need to split your data into training and validation sets for each fold. This requires reshaping your data multiple times.\n",
    "\n",
    "7. **Aggregating Data**:\n",
    "\n",
    "   - **Aggregating Time Series Data**: In time series analysis, you might need to aggregate data at different time intervals (e.g., daily to monthly) for modeling.\n",
    "\n",
    "The specific reshaping operation you need to perform depends on your data and the machine learning task you're working on. Libraries like NumPy, Pandas, and scikit-learn provide a wide range of functions and methods to help you reshape your data to suit your needs. The goal of data reshaping is to prepare your data in a format that allows your machine learning model to learn from it effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02eebf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train_mod=X_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9678de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mod=X_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a76d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efa2ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mod=y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "666ff27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mod=y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82d1a9",
   "metadata": {},
   "source": [
    "# It appears that you're creating a Support Vector Machine (SVM) classifier using scikit-learn's `SVC` class with a linear kernel. Here's a breakdown of what this code does:\n",
    "\n",
    "1. Import scikit-learn's SVM module:\n",
    "\n",
    "   Before using the `SVC` class, make sure to import it:\n",
    "\n",
    "   ```python\n",
    "   from sklearn import svm\n",
    "   ```\n",
    "\n",
    "2. Create an SVM classifier with a linear kernel:\n",
    "\n",
    "   The code you provided creates an SVM classifier object called `model` with a linear kernel. The linear kernel is one of the kernel functions used in SVM, and it is suitable for linearly separable datasets. In simple terms, it's used when you expect your data to have a linear boundary that separates different classes.\n",
    "\n",
    "   ```python\n",
    "   model = svm.SVC(kernel='linear')\n",
    "   ```\n",
    "\n",
    "   You can replace `'linear'` with other kernel types like `'rbf'` (Radial Basis Function), `'poly'` (Polynomial), etc., depending on the characteristics of your data and the problem you are trying to solve. Each kernel type has its own advantages and may perform better on different types of data.\n",
    "\n",
    "3. Train the SVM model:\n",
    "\n",
    "   To train the SVM model, you'll typically use your training data (feature matrix `X_train` and target variable `y_train`). Here's an example of how you can train the model:\n",
    "\n",
    "   ```python\n",
    "   model.fit(X_train, y_train)\n",
    "   ```\n",
    "\n",
    "   - `X_train`: Your training set features.\n",
    "   - `y_train`: Your training set target labels.\n",
    "\n",
    "4. Make predictions with the trained model:\n",
    "\n",
    "   After training, you can use the trained `model` to make predictions on new, unseen data (feature matrix `X_test`). Here's how you can do it:\n",
    "\n",
    "   ```python\n",
    "   y_pred = model.predict(X_test)\n",
    "   ```\n",
    "\n",
    "   - `X_test`: Your testing set features.\n",
    "   - `y_pred`: The predicted labels for your testing set based on the trained model.\n",
    "\n",
    "This code snippet sets up an SVM classifier with a linear kernel, but for practical use, you would typically load your own dataset, split it into training and testing sets, and then train and evaluate the model using your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7c9c898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_mod,y_train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eaaa8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mod=model.predict(X_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b29ff650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d33478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_mod,y_pred_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ac3d6",
   "metadata": {},
   "source": [
    "# DATA MODELLING USING THE KNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fb27ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "418f2481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c49de738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e74af87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7ba74",
   "metadata": {},
   "source": [
    "# The k-Nearest Neighbors (KNN) algorithm is a simple yet effective machine learning algorithm used for both classification and regression tasks. Its fundamental principle is based on the idea that data points with similar features tend to belong to the same class or have similar target values. KNN makes predictions by finding the K training data points that are nearest to a new, unseen data point and then using majority voting (for classification) or averaging (for regression) to determine the prediction. Here's how KNN works step by step:\n",
    "\n",
    "1. **Initialization**:\n",
    "   \n",
    "   - Choose the number of neighbors, K, which is a hyperparameter that you need to specify in advance. K represents the number of nearest neighbors to consider when making predictions.\n",
    "\n",
    "2. **Training**:\n",
    "\n",
    "   - The KNN algorithm stores the entire training dataset, which consists of feature vectors and their corresponding labels (for classification) or target values (for regression).\n",
    "\n",
    "3. **Prediction**:\n",
    "\n",
    "   - Given a new, unseen data point (a feature vector), the algorithm identifies the K training data points that are closest to the new data point based on a distance metric (commonly Euclidean distance).\n",
    "\n",
    "4. **Majority Voting (Classification)**:\n",
    "\n",
    "   - For classification tasks, KNN performs majority voting among the K nearest neighbors. It counts the number of neighbors belonging to each class and assigns the class with the highest count as the predicted class for the new data point.\n",
    "\n",
    "   - The choice of class label is based on the class labels of the majority of the K neighbors. In case of a tie, the algorithm can use different strategies, such as weighting the votes based on the distance to break the tie.\n",
    "\n",
    "5. **Averaging (Regression)**:\n",
    "\n",
    "   - For regression tasks, KNN calculates the average (or weighted average) of the target values of the K nearest neighbors. This average becomes the predicted target value for the new data point.\n",
    "\n",
    "   - If weighted averaging is used, closer neighbors may have a greater influence on the prediction than those farther away. Weights can be based on the distance or other factors.\n",
    "\n",
    "6. **Output**:\n",
    "\n",
    "   - KNN produces the final prediction for the new data point, either a class label (for classification) or a numerical value (for regression).\n",
    "\n",
    "Key Considerations and Notes:\n",
    "\n",
    "- The choice of distance metric (commonly Euclidean, Manhattan, or Minkowski distance) can significantly impact the results, so it's essential to choose an appropriate metric for your data.\n",
    "\n",
    "- The value of K is a critical hyperparameter that influences the algorithm's performance. A smaller K might lead to overfitting, while a larger K may introduce bias.\n",
    "\n",
    "- KNN is a non-parametric algorithm, meaning it does not make any assumptions about the underlying data distribution. It can work well for both linear and non-linear data.\n",
    "\n",
    "- KNN can be sensitive to the scaling of features, so it's often a good practice to standardize or normalize your data.\n",
    "\n",
    "- The computational complexity of KNN can be relatively high, especially for large datasets, as it requires calculating distances to all data points in the training set. This can be mitigated with efficient data structures like KD-trees or ball trees.\n",
    "\n",
    "- KNN is a lazy learner, meaning it doesn't build an explicit model during training. Instead, it memorizes the training data and makes predictions on-the-fly during testing.\n",
    "\n",
    "- KNN's performance can be influenced by the choice of K, the distance metric, and the handling of ties. Experimentation and cross-validation are often used to determine suitable settings for these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcfbf37",
   "metadata": {},
   "source": [
    "# The code you provided creates a K-nearest neighbors (KNN) classifier with `n_neighbors=1` and assigns it to the variable `knn`. The line `knn` by itself is simply a reference to the KNN classifier object you created. This allows you to use the `knn` variable to train the classifier, make predictions, and perform other operations.\n",
    "\n",
    "Here's how you can use the `knn` classifier object to train it and make predictions:\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a KNN classifier with k=1\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Assuming you have training data X_train and corresponding labels y_train\n",
    "knn.fit(X_train, y_train)  # Train the KNN classifier\n",
    "\n",
    "# Assuming you have test data X_test\n",
    "y_pred = knn.predict(X_test)  # Make predictions on the test data\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "- `knn.fit(X_train, y_train)` trains the KNN classifier on the training data (`X_train` features and `y_train` labels).\n",
    "\n",
    "- `knn.predict(X_test)` uses the trained classifier to make predictions on new, unseen data (`X_test` features), and the results are stored in the `y_pred` variable.\n",
    "\n",
    "You can then use `y_pred` to evaluate the model's performance or for other downstream tasks. Adjusting the value of `n_neighbors` will affect the number of neighbors considered when making predictions, and you can experiment with different values to find the best setting for your specific machine learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2bb2782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49a0c724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d1e1720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([4,5,6,2])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf1fb17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([a])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e6161",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9935b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fc1ee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg=LogisticRegression()\n",
    "logReg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a96f190e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.predict([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a992a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
